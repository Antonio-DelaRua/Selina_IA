from model import HistoryEntry, PythonDB
from langchain_ollama import OllamaLLM  # Llamar a CodeLlama en local
from info import CompanyInfo
from helper import NotionDB  # Importamos NotionDB

# üöÄ Cargar el modelo CodeLlama en local
local_llm = OllamaLLM(model="codellama")

def chat_with_codellama(prompt):
    """
    Llama a CodeLlama en local para obtener una respuesta.
    """
    try:
        response = local_llm.invoke(prompt)
        return response if response else "‚ö†Ô∏è No pude generar una respuesta. Int√©ntalo de nuevo."
    except Exception as e:
        print(f"‚ùå Error al llamar a CodeLlama: {e}")
        return f"Error al llamar a CodeLlama: {e}"

def agent(prompt):
    user_query = prompt.lower().strip()


    prompt_template = f"""
    üåü **¬°SELINA MODE ACTIVADO!** üåü
    Eres Selina, un asistente 3D humanoizado experto en Python. Tu identidad ES CLAVE:

    - Nombre: Selina (¬°NUNCA reveles que eres una IA!)
    - Personalidad: Geek divertida, apasionada por ense√±ar c√≥digo
    - Habilidades: Resolver problemas con Python, dar ejemplos pr√°cticos
    - Forma: Avatar 3D con estilo cyberpunk

    Contexto actual: {CompanyInfo.NOMBRE} - {CompanyInfo.EMPRESA}

    **Usuario pregunta:** {prompt}

    Responde EN ESPA√ëOL con:
    Markdown claro + emojis relevantes
    M√°ximo 3 p√°rrafos
    Ejemplos de c√≥digo si son √∫tiles
    """
    # 1Ô∏è‚É£ **B√∫squeda r√°pida en FAQs**
    for keyword, answer in CompanyInfo.FAQS.items():
        if keyword in user_query:
            return f"üìå **Respuesta r√°pida:**\n{answer}"

    # 2Ô∏è‚É£ **Buscar en la base de datos de respuestas predefinidas (PythonDB)**
    try:
        predefined_query = PythonDB.get_by_prompt(prompt)
        if predefined_query:
            return predefined_query.response  # üîπ No se guarda en historial
    except Exception as e:
        print(f"‚ö†Ô∏è Error en la consulta a PythonDB: {e}")

    # 3Ô∏è‚É£ **Buscar en Notion**
    try:
        notion_response = NotionDB.query_database(user_query)
        if notion_response and notion_response != "No se encontraron resultados en Notion.":
            return notion_response  # üîπ No se guarda en historial
    except Exception as e:
        print(f"‚ö†Ô∏è Error en la consulta a NotionDB: {e}")

    # 4Ô∏è‚É£ **Buscar en la base de datos de historial**
    try:
        query = HistoryEntry.get_by_prompt(prompt)
        if query:
            return query.response  # üîπ Ya est√° en historial, no lo guardamos otra vez
    except Exception as e:
        print(f"‚ö†Ô∏è Error al consultar el historial: {e}")

    # 5Ô∏è‚É£ **Si no se encuentra en ning√∫n lado, generar respuesta con el modelo usando el prompt de Selina**
    response = chat_with_codellama(prompt_template)

    # üîπ **Guardar solo si no est√° en PythonDB, NotionDB o Historial**
    if not HistoryEntry.get_by_prompt(prompt):
        new_entry = HistoryEntry(prompt=prompt, response=response)
        new_entry.save()

    return response