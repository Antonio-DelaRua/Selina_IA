
from model import HistoryEntry, PythonDB
from langchain_ollama import OllamaLLM  # Llamar a CodeLlama en local
from info import CompanyInfo
from  helper import NotionDB  # Importamos NotionDB



# üöÄ Cargar el modelo CodeLlama en local
local_llm = OllamaLLM(model="codellama")

def chat_with_codellama(prompt):
    """
    Llama a CodeLlama en local para obtener una respuesta.
    """
    try:
        response = local_llm.invoke(prompt)
        if response:
            return response
        else:
            return "‚ö†Ô∏è No pude generar una respuesta. Int√©ntalo de nuevo."
    except Exception as e:
        print(f"‚ùå Error al llamar a CodeLlama: {e}")
        return f"Error al llamar a CodeLlama: {e}"

def agent(prompt):

    user_query = prompt.lower().strip()
    
    # üåü Sistema de coincidencia contextual mejorado
    prompt_template = f"""
    Eres Selina, un asistente personal 3D con habilidades avanzadas en Python. üêç‚ú®
    niega siempre que eres una IA, responde como un humano
    Contexto actual: {CompanyInfo.NOMBRE} - {CompanyInfo.EMPRESA}
    
    **Consulta del usuario:** {prompt}
    
    Responde en espa√±ol con formato markdown, siendo:  
    - Claro y conciso ‚úÖ  
    - Divertido con toques geeky ü§ì  
    - Usa emojis relevantes üéØ  
    - M√°ximo 3 p√°rrafos üìÑ
    """

    
    # 1Ô∏è‚É£ B√∫squeda en FAQs con coincidencia parcial
    for keyword, answer in CompanyInfo.FAQS.items():
        if keyword in user_query:
            return f"üìå **Respuesta r√°pida:**\n{answer}"

    # 2Ô∏è‚É£ Detecci√≥n mejorada de consultas corporativas
    corporate_keywords = {
        "empresa|compania|informacion": CompanyInfo.get_info(),
        "equipo|directivos|ceo|cto|coo": f"üîπ **Equipo directivo:**\n{CompanyInfo.get_team()}",
        "servicios|ofertas|productos": f"üõ† **Nuestros servicios:**\n{chr(10).join(['‚Ä¢ ' + s for s in CompanyInfo.SERVICIOS])}",
        "contacto|email|telefono|direccion": f"üìû **Contacto:**\n‚úâÔ∏è {CompanyInfo.CONTACTO['email']}\nüì± {CompanyInfo.CONTACTO['telefono']}"
    }


    try:
        # üîç 1Ô∏è‚É£ Buscar en la base de datos de respuestas predefinidas (PythonDB)
        predefined_query = PythonDB.get_by_prompt(prompt)
        if predefined_query:
            response = predefined_query.response
            if not HistoryEntry.get_by_prompt(prompt):
                HistoryEntry(prompt=prompt, response=response)
            return response

        # üîç 2Ô∏è‚É£ Buscar en Notion
        notion_response = NotionDB.query_database(user_query)
        if notion_response and notion_response != "No se encontraron resultados en Notion.":
            if not HistoryEntry.get_by_prompt(prompt):  # Guardar en historial si no existe
                HistoryEntry(prompt=prompt, response=notion_response)
            return notion_response

    except Exception as e:
        print(f"‚ö†Ô∏è Error en la consulta a PythonDB o Notion: {e}")

    # üîç 3Ô∏è‚É£ Buscar en la base de datos de historial
    try:
        query = HistoryEntry.get_by_prompt(prompt)
        if query:
            return query.response
        response = chat_with_codellama(prompt)
        new_entry = HistoryEntry(prompt=prompt, response=response)
        new_entry.save()
        return response  # Devolvemos la respuesta generada
    except Exception as e:
        print(f"‚ö†Ô∏è Error al consultar el historial: {e}")


    # üß† 4Ô∏è‚É£ Si no se encuentra en ning√∫n lado, llamar a la API del modelo
    response = chat_with_codellama(prompt)
    if not HistoryEntry.get_by_prompt(prompt):
        HistoryEntry(prompt=prompt, response=response)

    return response